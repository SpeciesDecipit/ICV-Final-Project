{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "ICV Project Try #1.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "uz-y_pE0PYaV"
   },
   "source": [
    "from torchvision import models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from shutil import copyfile, rmtree\n",
    "import sys\n",
    "from torch.utils.data import random_split\n",
    "from sys import exit\n",
    "from os.path import join, basename, dirname, exists\n",
    "from torch.optim import lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "from os.path import join\n",
    "import logging\n",
    "import copy\n",
    "from torchvision.datasets import ImageFolder\n",
    "from copy import deepcopy "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6I1ykeGURc6w"
   },
   "source": [
    "def get_data_extract():\n",
    "    \"\"\"Method downloads dataset.\"\"\"\n",
    "    if \"food-101\" in os.listdir():\n",
    "        print(\"Dataset already exists\")\n",
    "    else:\n",
    "        print(\"Downloading the data...\")\n",
    "        !wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
    "        print(\"Dataset downloaded!\")\n",
    "        print(\"Extracting data..\")\n",
    "        !tar xzvf food-101.tar.gz &> /dev/null\n",
    "        print(\"Extraction done!\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TsXBaPz8RiY7",
    "outputId": "3fdf4873-911d-41d4-980c-a09f63042dee",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    }
   },
   "source": [
    "get_data_extract()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Downloading the data...\n",
      "--2020-09-23 18:27:19--  http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
      "Resolving data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)... 129.132.52.162\n",
      "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.162|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://data.vision.ee.ethz.ch/cvl/food-101.tar.gz [following]\n",
      "--2020-09-23 18:27:19--  https://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
      "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.162|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4996278331 (4.7G) [application/x-gzip]\n",
      "Saving to: ‘food-101.tar.gz’\n",
      "\n",
      "food-101.tar.gz     100%[===================>]   4.65G  52.5MB/s    in 2m 8s   \n",
      "\n",
      "2020-09-23 18:29:27 (37.2 MB/s) - ‘food-101.tar.gz’ saved [4996278331/4996278331]\n",
      "\n",
      "Dataset downloaded!\n",
      "Extracting data..\n",
      "Extraction done!\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DiaipNpmaX5b",
    "outputId": "3fc43562-ed42-4c2e-cdbf-803623cc3b07",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    }
   },
   "source": [
    "# Split data in 3 parts: train - 75%, validation - 15% and test - 15\n",
    "# Also, we use partial_coefficient to use only part of whole dataset\n",
    "# partial_coefficient = 1 means use 100% of dataset\n",
    "partial_coefficient = 1\n",
    "dataset = ImageFolder('./food-101/images')\n",
    "dataset_length = len(dataset)\n",
    "train_size = int(dataset_length * 0.70 * partial_coefficient)\n",
    "val_size = int(dataset_length * 0.15 * partial_coefficient)\n",
    "test_size = int(dataset_length * 0.15 * partial_coefficient)\n",
    "train_subset, val_subset, test_subset, _ = random_split(\n",
    "    dataset,\n",
    "    [\n",
    "        train_size,\n",
    "        val_size,\n",
    "        test_size,\n",
    "        dataset_length - sum([train_size, val_size, test_size]),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Apply transformations on data\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    'val': transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    'test': transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Initialization train, validation and test pytorch dataloaders\n",
    "train_subset.dataset = deepcopy(dataset)\n",
    "train_subset.dataset.transform = data_transforms['train']\n",
    "\n",
    "val_subset.dataset = deepcopy(dataset)\n",
    "val_subset.dataset.transform = data_transforms['val']\n",
    "\n",
    "test_subset.dataset.transform = data_transforms['test']\n",
    "\n",
    "train = torch.utils.data.DataLoader(\n",
    "    train_subset, batch_size=8, shuffle=True, num_workers=4\n",
    ")\n",
    "val = torch.utils.data.DataLoader(val_subset, batch_size=8, shuffle=True, num_workers=4)\n",
    "test = torch.utils.data.DataLoader(\n",
    "    test_subset, batch_size=8, shuffle=True, num_workers=4\n",
    ")\n",
    "\n",
    "dataloaders = {'train': train, 'val': val, 'test': test}\n",
    "\n",
    "print(\n",
    "    *list(map(lambda ds: f'{ds[0]}: {len(ds[1].dataset)}', dataloaders.items())),\n",
    "    sep='\\n',\n",
    ")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "train: 70700\n",
      "val: 15150\n",
      "test: 15150\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Mo30kIexU4iU"
   },
   "source": [
    "# Prepare some folders\n",
    "root_folder = './food-101'\n",
    "plots_folder = './plots'\n",
    "models_folder = './models'\n",
    "images_folder = join(root_folder, 'images')\n",
    "if not os.path.exists(plots_folder):\n",
    "    os.makedirs(plots_folder) \n",
    "\n",
    "if not os.path.exists(models_folder):\n",
    "    os.makedirs(models_folder)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1nzSKTchQvgU"
   },
   "source": [
    "class SliceBranch(torch.nn.Module):\n",
    "    \"\"\"Horizontal SliceBranch NN.\"\"\"\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SliceBranch, self).__init__()\n",
    "        kernel_size = (224, 5)\n",
    "        self.wide_conv = torch.nn.Conv2d(\n",
    "            input_size, output_size, kernel_size, stride=1, padding=0, bias=True\n",
    "        )\n",
    "        self.bn = torch.nn.BatchNorm2d(output_size)\n",
    "        self.maxpool = torch.nn.MaxPool2d((1, 5))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = F.relu(self.bn(self.wide_conv(x)))\n",
    "        out2 = self.maxpool(out1)\n",
    "        out3 = self.maxpool(out2)\n",
    "        out4 = self.maxpool(out3)\n",
    "        return out4\n",
    "\n",
    "\n",
    "class WideResnet101PlusSlice(torch.nn.Module):\n",
    "    \"\"\"Combination pretrained WideResnet101 NN with out SliceBranch.\"\"\"\n",
    "    def __init__(self, nb_classes, drop_prob):\n",
    "        super(WideResnet101PlusSlice, self).__init__()\n",
    "        self.slice_branch = SliceBranch(3, 320)\n",
    "        self.wide_res101_pretrained = torch.hub.load(\n",
    "            'pytorch/vision', 'wide_resnet101_2', pretrained=True\n",
    "        )\n",
    "        self.res101_branch = torch.nn.Sequential(\n",
    "            *list(self.wide_res101_pretrained.children())[:-1]\n",
    "        )\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(2368, 2048)\n",
    "        self.dropout = nn.Dropout(p=drop_prob)\n",
    "        self.fc2 = torch.nn.Linear(2048, nb_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        s_b = self.slice_branch(x)\n",
    "        r_b = self.res101_branch(x)\n",
    "        out = torch.cat([s_b, r_b], dim=1)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ppclg-PvWJEc"
   },
   "source": [
    "def train_val_model(model, criterion, optimizer, scheduler, num_epochs=15):\n",
    "    \"\"\"Method train model and calculates intermediates accuracy. \"\"\"\n",
    "    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    best_accuracy = 0.0\n",
    "    train_epoch_losses = []\n",
    "    val_epoch_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        print('\\nEpoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('Learning rate {}'.format(scheduler.get_lr()))\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            model.train() if phase == 'train' else model.eval()\n",
    "\n",
    "            running_losses = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, predictions = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_losses += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(predictions == labels.data)\n",
    "\n",
    "            epoch_loss = running_losses / len(dataloaders[phase].dataset)\n",
    "            epoch_accuracy = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            if phase == 'train':\n",
    "                train_epoch_losses.append(epoch_loss)\n",
    "            else:\n",
    "                val_epoch_losses.append(epoch_loss)\n",
    "            print(\n",
    "                '\\t{} loss: {:.4f}, {} accuracy: {:.4f}'.format(\n",
    "                    phase, epoch_loss, phase, epoch_accuracy\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if phase == 'val' and epoch_accuracy > best_accuracy:\n",
    "                best_accuracy = epoch_accuracy\n",
    "                best_model_weights = copy.deepcopy(model.state_dict())\n",
    "                torch.save(best_model_weights, join(models_folder, '/content/drive/My Drive/icv project/checkpoint4.pth'))\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "    print('Best validation accuracy: {:4f}'.format(best_accuracy))\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    return model, train_epoch_losses, val_epoch_losses\n",
    "\n",
    "\n",
    "def configure_run_model(\n",
    "    nb_classes, drop_prob, multi_gpu, lr_step_size, lr_step_gamma, epochs\n",
    "):\n",
    "    \"\"\"Method initializes all necessary stuff for model training.\"\"\"\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model = WideResnet101PlusSlice(nb_classes, drop_prob)\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "    if multi_gpu:\n",
    "        print(\"Using {} GPUs.\".format(torch.cuda.device_count()))\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(\n",
    "        optimizer, step_size=lr_step_size, gamma=lr_step_gamma,\n",
    "    )\n",
    "\n",
    "    model = train_val_model(model, criterion, optimizer, exp_lr_scheduler, epochs)\n",
    "    return model"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wceANoxHX-bO",
    "outputId": "d5e2f11a-d5d5-438b-e579-1423ef6af4e2",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "# Initialize the CUDE cores\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    total_gpus = torch.cuda.device_count()\n",
    "    print('Total number of GPUs:{}'.format(total_gpus))\n",
    "    if total_gpus == 1:\n",
    "        multi_gpu = False\n",
    "    elif total_gpus > 1:\n",
    "        multi_gpu = True"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Total number of GPUs:1\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ESraTOM0cM11",
    "outputId": "32e4095c-b333-4c92-cc7c-99a5f0879da9",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "# Train model\n",
    "model, train_losses, val_losses = configure_run_model(\n",
    "    len(dataset.classes), \n",
    "    drop_prob=0.5, \n",
    "    multi_gpu=multi_gpu,\n",
    "    lr_step_size=40,\n",
    "    lr_step_gamma=0.1,\n",
    "    epochs=100,\n",
    ")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_master\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0/99\n",
      "Learning rate [0.01]\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:351: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\ttrain loss: 4.5468, train accuracy: 0.0381\n",
      "\tval loss: 3.9815, val accuracy: 0.0886\n",
      "\n",
      "Epoch 1/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 3.7189, train accuracy: 0.1421\n",
      "\tval loss: 3.0532, val accuracy: 0.2747\n",
      "\n",
      "Epoch 2/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 2.9393, train accuracy: 0.2952\n",
      "\tval loss: 2.1183, val accuracy: 0.4708\n",
      "\n",
      "Epoch 3/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 2.9506, train accuracy: 0.3030\n",
      "\tval loss: 5.6043, val accuracy: 0.0691\n",
      "\n",
      "Epoch 4/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 2.7362, train accuracy: 0.3447\n",
      "\tval loss: 2.1855, val accuracy: 0.4827\n",
      "\n",
      "Epoch 5/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 2.3481, train accuracy: 0.4245\n",
      "\tval loss: 1.7702, val accuracy: 0.5735\n",
      "\n",
      "Epoch 6/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 2.0983, train accuracy: 0.4803\n",
      "\tval loss: 1.8305, val accuracy: 0.5971\n",
      "\n",
      "Epoch 7/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 1.9653, train accuracy: 0.5114\n",
      "\tval loss: 1.5181, val accuracy: 0.6225\n",
      "\n",
      "Epoch 8/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 1.9434, train accuracy: 0.5181\n",
      "\tval loss: 1.6296, val accuracy: 0.6374\n",
      "\n",
      "Epoch 9/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 1.7906, train accuracy: 0.5502\n",
      "\tval loss: 1.3782, val accuracy: 0.6581\n",
      "\n",
      "Epoch 10/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 2.0123, train accuracy: 0.5109\n",
      "\tval loss: 2.2731, val accuracy: 0.4557\n",
      "\n",
      "Epoch 11/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 2.0068, train accuracy: 0.5040\n",
      "\tval loss: 1.4889, val accuracy: 0.6407\n",
      "\n",
      "Epoch 12/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 1.7263, train accuracy: 0.5673\n",
      "\tval loss: 1.3106, val accuracy: 0.6770\n",
      "\n",
      "Epoch 13/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 1.7246, train accuracy: 0.5677\n",
      "\tval loss: 1.3229, val accuracy: 0.6818\n",
      "\n",
      "Epoch 14/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 1.5848, train accuracy: 0.5990\n",
      "\tval loss: 1.2935, val accuracy: 0.6941\n",
      "\n",
      "Epoch 15/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 1.5084, train accuracy: 0.6178\n",
      "\tval loss: 1.2778, val accuracy: 0.7087\n",
      "\n",
      "Epoch 16/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 1.4608, train accuracy: 0.6282\n",
      "\tval loss: 1.2218, val accuracy: 0.7116\n",
      "\n",
      "Epoch 17/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 1.4156, train accuracy: 0.6392\n",
      "\tval loss: 1.3953, val accuracy: 0.7059\n",
      "\n",
      "Epoch 18/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 1.3703, train accuracy: 0.6502\n",
      "\tval loss: 1.2287, val accuracy: 0.7145\n",
      "\n",
      "Epoch 19/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 1.3440, train accuracy: 0.6555\n",
      "\tval loss: 1.2541, val accuracy: 0.7222\n",
      "\n",
      "Epoch 20/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 1.3364, train accuracy: 0.6591\n",
      "\tval loss: 1.9467, val accuracy: 0.7277\n",
      "\n",
      "Epoch 21/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 1.2694, train accuracy: 0.6732\n",
      "\tval loss: 4.6151, val accuracy: 0.7158\n",
      "\n",
      "Epoch 22/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 1.2338, train accuracy: 0.6793\n",
      "\tval loss: 2.2900, val accuracy: 0.7338\n",
      "\n",
      "Epoch 23/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 1.2231, train accuracy: 0.6851\n",
      "\tval loss: 2.0205, val accuracy: 0.7364\n",
      "\n",
      "Epoch 24/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 1.1811, train accuracy: 0.6944\n",
      "\tval loss: 1.4847, val accuracy: 0.7421\n",
      "\n",
      "Epoch 25/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 1.1678, train accuracy: 0.6970\n",
      "\tval loss: 1.1874, val accuracy: 0.7442\n",
      "\n",
      "Epoch 26/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 1.1436, train accuracy: 0.7034\n",
      "\tval loss: 1.3011, val accuracy: 0.7545\n",
      "\n",
      "Epoch 27/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 1.1164, train accuracy: 0.7088\n",
      "\tval loss: 1.4580, val accuracy: 0.7449\n",
      "\n",
      "Epoch 28/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 1.1023, train accuracy: 0.7121\n",
      "\tval loss: 1.9066, val accuracy: 0.7532\n",
      "\n",
      "Epoch 29/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 1.3025, train accuracy: 0.6881\n",
      "\tval loss: 3.1118, val accuracy: 0.4933\n",
      "\n",
      "Epoch 30/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 1.5397, train accuracy: 0.6371\n",
      "\tval loss: 1.1304, val accuracy: 0.7327\n",
      "\n",
      "Epoch 31/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 1.1454, train accuracy: 0.7010\n",
      "\tval loss: 1.0176, val accuracy: 0.7564\n",
      "\n",
      "Epoch 32/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 1.0830, train accuracy: 0.7186\n",
      "\tval loss: 1.0150, val accuracy: 0.7640\n",
      "\n",
      "Epoch 33/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 1.0371, train accuracy: 0.7264\n",
      "\tval loss: 1.0253, val accuracy: 0.7591\n",
      "\n",
      "Epoch 34/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 1.0245, train accuracy: 0.7294\n",
      "\tval loss: 1.0344, val accuracy: 0.7656\n",
      "\n",
      "Epoch 35/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 1.0062, train accuracy: 0.7360\n",
      "\tval loss: 1.0463, val accuracy: 0.7666\n",
      "\n",
      "Epoch 36/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 0.9759, train accuracy: 0.7434\n",
      "\tval loss: 1.0246, val accuracy: 0.7642\n",
      "\n",
      "Epoch 37/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 0.9634, train accuracy: 0.7470\n",
      "\tval loss: 0.9696, val accuracy: 0.7744\n",
      "\n",
      "Epoch 38/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 0.9461, train accuracy: 0.7492\n",
      "\tval loss: 1.0529, val accuracy: 0.7704\n",
      "\n",
      "Epoch 39/99\n",
      "Learning rate [0.01]\n",
      "\ttrain loss: 0.9293, train accuracy: 0.7548\n",
      "\tval loss: 1.0444, val accuracy: 0.7642\n",
      "\n",
      "Epoch 40/99\n",
      "Learning rate [0.0001]\n",
      "\ttrain loss: 0.7037, train accuracy: 0.8114\n",
      "\tval loss: 0.8704, val accuracy: 0.8054\n",
      "\n",
      "Epoch 41/99\n",
      "Learning rate [0.001]\n",
      "\ttrain loss: 0.6475, train accuracy: 0.8271\n",
      "\tval loss: 0.8659, val accuracy: 0.8050\n",
      "\n",
      "Epoch 42/99\n",
      "Learning rate [0.001]\n",
      "\ttrain loss: 0.6233, train accuracy: 0.8322\n",
      "\tval loss: 0.8722, val accuracy: 0.8071\n",
      "\n",
      "Epoch 43/99\n",
      "Learning rate [0.001]\n",
      "\ttrain loss: 0.6010, train accuracy: 0.8394\n",
      "\tval loss: 0.8663, val accuracy: 0.8075\n",
      "\n",
      "Epoch 44/99\n",
      "Learning rate [0.001]\n",
      "\ttrain loss: 0.5848, train accuracy: 0.8435\n",
      "\tval loss: 0.8625, val accuracy: 0.8094\n",
      "\n",
      "Epoch 45/99\n",
      "Learning rate [0.001]\n",
      "\ttrain loss: 0.5715, train accuracy: 0.8460\n",
      "\tval loss: 0.8714, val accuracy: 0.8064\n",
      "\n",
      "Epoch 46/99\n",
      "Learning rate [0.001]\n",
      "\ttrain loss: 0.5724, train accuracy: 0.8458\n",
      "\tval loss: 0.8649, val accuracy: 0.8101\n",
      "\n",
      "Epoch 47/99\n",
      "Learning rate [0.001]\n",
      "\ttrain loss: 0.5606, train accuracy: 0.8484\n",
      "\tval loss: 0.8623, val accuracy: 0.8100\n",
      "\n",
      "Epoch 48/99\n",
      "Learning rate [0.001]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RrFTyDqNdVmt",
    "outputId": "37a47491-26e2-4b03-ba36-d40530bfcfff",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "# Load trained model from checkpoint\n",
    "model = WideResnet101PlusSlice(len(dataset.classes), drop_prob=0.5)\n",
    "model.load_state_dict(torch.load('/content/drive/My Drive/icv project/49_epoch_full_dataset'))\n",
    "model = torch.nn.DataParallel(model)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_master\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Z-zqXVi141OQ",
    "outputId": "4766feb2-42f9-47c9-b76c-e91ca4e806fc",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    }
   },
   "source": [
    "# Calculate test, validation and train accuracy\n",
    "def evaluate_model(model, dataset):\n",
    "    model.eval()\n",
    "    running_corrects = 0    \n",
    "    with torch.no_grad():\n",
    "        for _, (inputs, labels) in enumerate(dataset):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(predictions == labels.data)\n",
    "            acc = running_corrects.double() / len(dataset.dataset)\n",
    "    return round(acc.item(), 2)   \n",
    "\n",
    "print(f'Train accuracy: {evaluate_model(model, dataloaders[\"train\"])}')\n",
    "print(f'Val accuracy: {evaluate_model(model, dataloaders[\"val\"])}')\n",
    "print(f'Test accuracy: {evaluate_model(model, dataloaders[\"test\"])}')"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.84\n",
      "Val accuracy: 0.91\n",
      "Test accuracy: 0.91\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jKpcokXagMxK",
    "outputId": "e4dea8f4-79ca-49d0-bbe3-480e6b1e7608",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "# Classification of random images from the Internet\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "idx_to_class = {id: class_name for class_name, id in dataset.class_to_idx.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    image = data_transforms['test'](Image.open('/content/delish-deviled-eggs-horizontal-1542055209.jpg'))\n",
    "    inputs = image.to(device)\n",
    "    outputs = model(inputs[None])\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "    print(idx_to_class[predictions.item()])"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "deviled_eggs\n"
     ],
     "name": "stdout"
    }
   ]
  }
 ]
}